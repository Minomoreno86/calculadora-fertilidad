# Contenido actualizado para: tests/test_generacion_informe.py

import pytest
from models import EvaluacionFertilidad
from logic.generacion_informe import generar_textos_pronostico

# El decorador @pytest.mark.parametrize ejecuta la prueba de abajo
# una vez por cada tupla en la lista.
@pytest.mark.parametrize("pronostico_inicial, categoria_esperada, emoji_esperado", [
    (20.0, "BUENO", ""),      # Caso 1: Pron贸stico Bueno
    (15.0, "BUENO", ""),      # Caso 2: L铆mite superior de Moderado
    (8.5, "MODERADO", ""),     # Caso 3: Pron贸stico Moderado
    (5.0, "MODERADO", ""),     # Caso 4: L铆mite superior de Bajo
    (4.9, "BAJO", ""),        # Caso 5: Pron贸stico Bajo
    (0.0, "BAJO", "")         # Caso 6: Pron贸stico Cero
])
def test_generacion_textos_pronostico(pronostico_inicial, categoria_esperada, emoji_esperado):
    """
    Prueba parametrizada que verifica la categor铆a y el emoji para
    m煤ltiples valores de pron贸stico.
    """
    # Esta es nuestra "plantilla" de prueba
    evaluacion = EvaluacionFertilidad()
    evaluacion.pronostico_numerico = pronostico_inicial
    
    generar_textos_pronostico(evaluacion)
    
    assert evaluacion.pronostico_categoria == categoria_esperada
    assert evaluacion.pronostico_emoji == emoji_esperado

# A煤n mantenemos la prueba del caso OTB por separado, ya que es una l贸gica diferente
def test_generar_texto_caso_otb():
    eval_otb = EvaluacionFertilidad()
    eval_otb.otb_factor = 0.0 # Simulamos que tiene OTB
    generar_textos_pronostico(eval_otb)
    assert eval_otb.pronostico_categoria == "REQUIERE TRATAMIENTO"